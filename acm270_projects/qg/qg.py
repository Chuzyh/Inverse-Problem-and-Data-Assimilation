# -*- coding: utf-8 -*-
"""QG.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EhQKat3p-5aGqJxWkjE6681uQ4qOohkY
"""

from ml_model import model
from physical_model import drymodel

import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from scipy.stats import multivariate_normal as mvn
import scipy
import cupy as cp

device = "cuda"



# The step of each of the models is 1.0, corresponding to ~6 hours
n_transient = 100
n_steps = 40

psi0 = np.random.randn(96, 192, 2)

psi = psi0
for i in range(n_transient):
    psi = drymodel(psi)

# Integrate forward numerical and ML model
psi0 = psi

psi = psi0
psis_phys = [psi0]
for i in range(n_steps):
    psi = drymodel(psi)
    psis_phys.append(psi)

psi = psi0
psis_ml = [psi0]
for i in range(n_steps):
    psi = model.predict(psi.transpose((1, 0, 2))[np.newaxis, :])[0, :, :, :].transpose((1, 0, 2))
    psis_ml.append(psi)

# Plot the RMSE between the physical and ML forecast
plt.plot(np.sqrt(np.mean((np.array(psis_ml) - np.array(psis_phys))**2, axis=(1, 2, 3))))

n_transient = 100
n_steps = 40

psi0 = np.random.randn(96, 192, 2)

psi = psi0
for i in range(n_transient):
    psi = drymodel(psi)

# Integrate forward numerical and ML model
psi0 = psi

psi = psi0
psis_phys = [psi0]
# True trajactory
for i in range(n_steps):
    psi = drymodel(psi)
    psis_phys.append(psi)

psis_phys = np.stack(psis_phys)

psi = psi0
psis_ml = [psi0]
# ML surroage
for i in range(n_steps):
    psi = model.predict(psi.transpose((1, 0, 2))[np.newaxis, :])[0, :, :, :].transpose((1, 0, 2))
    psis_ml.append(psi)

psis_ml = np.stack(psis_ml)

# True Observation Model

y_obs_true = psis_phys + 0.1 * np.random.randn(*psis_phys.shape)
y_obs_ml = psis_ml + 0.1 * np.random.randn(*psis_ml.shape)

def block_matrix_inverse(S, block_size):
    """
    Compute the inverse of a matrix S using the block matrix formula.

    Parameters:
    S (ndarray): The input matrix (2D NumPy array).
    block_size (int): Size of the first block (assumes square A).

    Returns:
    S_inv (ndarray): The inverse of S.
    """
    # Partition the matrix S into blocks
    A = S[:block_size, :block_size]
    B = S[:block_size, block_size:]
    C = S[block_size:, :block_size]
    D = S[block_size:, block_size:]

    # Compute A^-1
    A_inv = scipy.linalg.inv(A)

    # Compute Schur complement S22
    S22 = D - C @ A_inv @ B

    # Compute S22^-1
    S22_inv = scipy.linalg.inv(S22)

    # Compute the blocks of S^-1
    top_left = A_inv + A_inv @ B @ S22_inv @ C @ A_inv
    top_right = -A_inv @ B @ S22_inv
    bottom_left = -S22_inv @ C @ A_inv
    bottom_right = S22_inv

    # Assemble the full inverse matrix
    S_inv = np.block([
        [top_left, top_right],
        [bottom_left, bottom_right]
    ])

    return S_inv

def EnKF(E, y, gamma, num_E):
    '''
    H be the identity
    '''
    y = y.flatten()
    E = E.reshape(num_E, 96,192,2)
    for i in range(num_E):
        q =  model.predict(E[i].transpose((1, 0, 2))[np.newaxis, :])[0, :, :, :].transpose((1, 0, 2)) + np.random.randn(*E[i].shape)
        E[i] = q
    E = E.reshape(num_E,d)
    ens_mean = np.mean(E, axis=0)
    ens_residual = E - ens_mean
    # Compute forecast error covariance matrix C
    print("start calc C")
    C = np.cov(ens_residual.T)
    print("end calc C")
    # Localization step
    C_new = np.zeros_like(C)
    C_new = np.diag(np.diag(C)) + np.diag(np.diag(C, -1), -1)+ np.diag(np.diag(C, 1), 1)
    
    print("end calc C new")
    # Part 2: Analysis
    # Compute Kalman gain K similar to KF defined above
    S =   C_new  + 0.1* gamma
    S_inv = block_matrix_inverse(S, S.shape[1]//2)
    K = C_new  @ S_inv
    E_up = np.zeros_like(E)
    eta = np.random.randn(d)

    for i in range(num_E):
        y_mod = y + eta
        E_up[i] = (np.eye(d) - K ) @ E[i] + K @ y_mod

    return E_up

d = psi.flatten().shape[0]
x_0 = np.zeros(d)
Sigma_0 = np.eye(d)
Gamma = np.eye(d)
H = np.eye(d)
num_E = 10

ensemble_list = np.zeros((n_steps, num_E, d))
ensemble =  np.random.randn(num_E, d)
state_estimates_EnKF = np.zeros((n_steps, d))

for t in tqdm(range(n_steps)):
    ensemble = EnKF(ensemble, y_obs_ml[t], Gamma, num_E)
    ensemble_list[t] = ensemble

